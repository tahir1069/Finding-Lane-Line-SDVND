{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "***\n",
    "# Finding Lane Lines on the Road \n",
    "---\n",
    "\n",
    "\n",
    "## Overview \n",
    "---\n",
    "***\n",
    "When we drive a car, we use our eyes to see on the road. One of the first thing we need to drive is to keep track of lane lines on the road. Coming up to self-driving cars or driving assistance systems we need the system should track the lane lines to stay on its track. \n",
    "Our job is to teach the car how to drive itself in order to do that we have to teach the car how to perceive the world around it now when we drive we figure out how fast to drive where the lane lines are? And where to turn?  \n",
    "The goals steps of this project are the following:\n",
    "\n",
    "•\tMake a pipeline that finds lane lines on the road\n",
    "\n",
    "A car doesn’t have eyes but in self-driving cars we use cameras and other sensors to achieve a similar function. Now let’s see what the cameras sees around them. We can see the things automatically. So here our goal is to teach the car to identify and track the position of the lane lines in a series of images.\n",
    "Here are some of the features we can identify on the road in order to find lane lines on the road: \n",
    "\n",
    "•\tColor\n",
    "\n",
    "•\tShape\n",
    "\n",
    "•\tOrientation \n",
    "\n",
    "•\tPosition in Image\n",
    "<figure>\n",
    " <img src=\"examples/Original_Image_1.png\" width=\"580\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> This is a sample image to detect road lines on. </p> \n",
    "</figcaption>\n",
    "\n",
    "---\n",
    "***\n",
    "## Color Selection \n",
    "---\n",
    "*** \n",
    "For starting point, now Let’s try finding the lane lines using the color. The lane lines are usually white. To select a color, We actually sees, need to identify what it means in digital image. In digital domain images are made up of stack of three images: \n",
    "\n",
    "•\tRed \n",
    "\n",
    "•\tGreen \n",
    "\n",
    "•\tBlue\n",
    "<figure>\n",
    " <img src=\"examples/RGB Image.png\" width=\"580\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\">RGB Image</p> \n",
    " </figcaption>\n",
    "The images are sometime called color channels. Each of these color have values from 0-255 where 0 is the darkest possible value and 255 is the brightest possible values. If zero is dark and brightest is 255 than white will be [255,255,255]. Now getting this we define threshold for RGB image for white.\n",
    "<figure>\n",
    " <img src=\"examples/Color Selection.png\" width=\"580\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\">RGB Image after Color Thresholding</p> \n",
    " </figcaption>\n",
    " \n",
    "---\n",
    "***\n",
    "## Masking \n",
    "---\n",
    "***\n",
    "Now let’s focus on the region of the image which interests us. Namely the regions where the lane lines are. In this case we can assume the camera is mounted in front of the image and it took the image and region stays the same for every single image taken.\n",
    "<figure>\n",
    " <img src=\"examples/Masking.png\" width=\"580\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Masking the image to get some region of interest</p> \n",
    "</figcaption>\n",
    "Now we've seen how to mask out a region of interest in an image. Next, let's combine the mask and color selection to pull only the lane lines out of the image.\n",
    "<figure>\n",
    " <img src=\"examples/Color Selection and Masking.png\" width=\"580\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Color Selction and Masking Combined</p> \n",
    " </figcaption>\n",
    " \n",
    "---\n",
    "***\n",
    "## Computer Vision \n",
    "---\n",
    "***\n",
    "As it happens, lane lines are not always the same color, and even lines of the same color under different lighting conditions (day, night, etc.) may fail to be detected by our simple color selection.\n",
    "What we need is to take our algorithm to the next level to detect lines of any color using sophisticated computer vision methods.\n",
    "We will be using Python with OpenCV for computer vision work. OpenCV stands for Open-Source Computer Vision. \n",
    "*You can download the files following instructions at the end of this document.\n",
    "<figure>\n",
    " <img src=\"examples/OpenCV and Python.png\" width=\"580\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"examples/text-align: center;\"> </p> \n",
    " </figcaption>\n",
    "OpenCV contains extensive libraries of functions that you can use. The OpenCV libraries are well documented, so if you’re ever feeling confused about what the parameters in a particular function are doing, or anything else, you can find a wealth of information at opencv.org.\n",
    "\n",
    "---\n",
    "***\n",
    "## Edge Detection \n",
    "---\n",
    "***\n",
    "With edge detection our goal is to identify the boundaries of an image. So to do that first we convert to gray scale. And next we compute the gradient. In gradients the brightness of each pixels corresponds to the strength of the gradient at that point we will define edges by tracing out the pixels that follows the strongest gradient. By identifying edges we can even more easily detect object with their shapes.\n",
    "<figure>\n",
    " <img src=\"examples/Gray_Scale.png\" width=\"580\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Example Image</p> \n",
    "</figcaption>\n",
    "<figure>\n",
    " <img src=\"examples/Gray_Scale.png\" width=\"580\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Gray Scale</p> \n",
    " </figcaption>\n",
    "<figure>\n",
    " <img src=\"examples/Gradient.png\" width=\"580\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Gradient Image</p> \n",
    " </figcaption>\n",
    "---\n",
    "***\n",
    "## Hough Transform \n",
    "---\n",
    "***\n",
    "After doing edge detection the function gives edges in the form of dots. And these dots represents edges. Now it’s time to connect the dots. We could connect the dots with any kind of shapes in the image. For in this case we are interested in lane lines. To find lines we need to adapt a model of a line to the assortment of dots in our edge detected image keeping in mind image is a mathematical function we can apply equation of line.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y = mx+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case our model have two parameters m and b in image space a line is plotted x vs. y but in parameter space which we will call Hough space. In Hough space we can represent the same line as m vs. b instead. The Hough transform is just conversion from image space to Hough space. So characterization of a single line will be a point at a position m, b in Hough space. \n",
    "so our strategy to find lines in image space will be to find intersecting lines in Hough space we do this by dividing up the Hough space into a grid and define intersecting lines as all lines passing through a given grid cell. To do this first we run canny edge on our image and then finding lines in Hough space on edge detected image \n",
    "\n",
    "In this case, we are operating on the image masked edges (the output from Canny) and the output from HoughLinesP will be lines, which will simply be an array containing the endpoints (x1, y1, x2, y2) of all line segments detected by the transform operation. The other parameters define just what kind of line segments we're looking for. \n",
    "\n",
    "<figure>\n",
    " <img src=\"examples/Hough _Transform.png\" width=\"580\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Hough Transform (Detecting Some Lines in the image)</p> \n",
    " </figcaption> \n",
    "<figure>\n",
    " <img src=\"examples/Hough and Region Masking.png\" width=\"580\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Hough Transform to detect Lines in Region of Interest </p> \n",
    "</figcaption>\n",
    "As you can see I've detected lots of line segments. As in above image we have applied our technique to straight solid white lines, but what if we apply these techniques to a segmented lines the output will look some thing like:\n",
    "<figure>\n",
    " <img src=\"examples/line-segments-example.jpg\" width=\"580\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Hough Transform (Detecting Some Lines in the image)</p> \n",
    " </figcaption> \n",
    "---\n",
    "***\n",
    "## Exttrapolation \n",
    "---\n",
    "***\n",
    "Here we can see our algorithm does not work on segemented lines. To work on these lines we need to change our algorithm a bit. Hough transform gives solid lines as output. Taking these lines we need to design a new pipeline which can extrapolate these solid lines.\n",
    "Now we will apply moving averages technique to extrapolate lines. The figure below shows how this technique works and extrapolates either the right line or left line. Figure below shows how we need to extrapolate lines with their possible extension points.\n",
    "Extrapolation Algorithm steps:\n",
    "* Anchor the bottom of both left and right lanes.\n",
    "* Use the slope of both lines as a guide for extrapolation.\n",
    "* Determine which line has the highest point (close to horizon).\n",
    "* Extrapolate the other lane to match the alternate side.\n",
    "\n",
    "<figure>\n",
    " <img src=\"examples/extrapolation (2).jpg\" width=\"580\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Extrapolating Hough Lines</p> \n",
    " </figcaption>\n",
    " \n",
    " \n",
    "---\n",
    "***\n",
    "### Left Lane Extrapolation \n",
    "---\n",
    "***\n",
    "\n",
    "Xmin = Xmin\n",
    "\n",
    "Ymin = Ymin\n",
    "\n",
    "Xmin = (Ymax – Yintercept) / Slope\n",
    "\n",
    "Ymax = max(Ymax , Ymax-right-lane)\n",
    "\n",
    "---\n",
    "***\n",
    "### Right Lane Extrapolation \n",
    "---\n",
    "***\n",
    "\n",
    "Xmin = Xmin\n",
    "\n",
    "Ymin = Ymin\n",
    "\n",
    "Xmin = (Ymax – Yintercept) / Slope\n",
    "\n",
    "Ymax = max(Ymax , Ymax-Left-lane)\n",
    "<figure>\n",
    " <img src=\"examples/solidWhiteRight.jpeg\" width=\"580\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Extrapolating Hough Lines</p> \n",
    " </figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "***\n",
    "### Reflections\n",
    "---\n",
    "***\n",
    "Congratulations on finding the lane lines! As the final step in this project, we would like you to share your thoughts on your lane finding pipeline... specifically, how could you imagine making your algorithm better / more robust? Where will your current algorithm be likely to fail? \n",
    "\n",
    "---\n",
    "   \n",
    "***\n",
    "### ShortComings \n",
    "---\n",
    "***\n",
    "* This approach could not work properly:\n",
    "    * if the camera is placed at a different position\n",
    "    * if other vehicles in front are occluding the view\n",
    "    * if one or more lines are missing\n",
    "    * at different weather and light condition (fog, rain, or at night).\n",
    "    * More robust outlier detector is needed to be implement\n",
    " \n",
    "---\n",
    "***\n",
    "## Improvements \n",
    "---\n",
    "***\n",
    "* To cater shadow or some other situations images can be sharpened so that pixel transitions resulting boarders can easily be detetcted (some high pass filters).\n",
    "* instead of canny edge detection sobel edge detector can be used which is alot more robust than canny.\n",
    "* Morphology can also be implemented to make the algorithm more robust.\n",
    "* Histogram equalization is also another technique which can be used to increase image contrast.\n",
    "* Perform a color selection in the HSV space, instead of doing it in the RGB images\n",
    "* Update the ROI mask dynamically\n",
    "* Perform a segmentation of the road\n",
    "* If a line is not detected, we could estimate the current slope using the previous estimations and/or the other line detection\n",
    "\n",
    "---\n",
    "***\n",
    "## Requirements \n",
    "---\n",
    "***\n",
    "* Instal Anacnda\n",
    "* From conda prompt goto Finiding Lane Lines SDVND and run the following command:\n",
    "    *conda env create -f virtual_environment_windows.yml\n",
    "* Now open anaconda navigator from the left upper corner change from root to virtual environement\n",
    "* Run Spyder\n",
    "* Run the main_file.py and **enjoy!!!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
